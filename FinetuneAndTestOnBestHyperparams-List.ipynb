{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from FinetuneCNN import Finetune\n",
    "import numpy as np\n",
    "import utils\n",
    "import configure\n",
    "import tensorflow as tf\n",
    "import bot\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "\n",
    "pjoin = os.path.join\n",
    "\n",
    "# This code will fine-tune with best hyperparams (saved in all_folds.csv) again, then test it on test set.\n",
    "# the model's weight from fine-tuning in this code\n",
    "# will be saved in the same finetune_weight_path of fine-tuning time. \n",
    "# (the new dir will be created for logging only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define path location here\n",
    "dirpath = './logs'\n",
    "\n",
    "# define list of finish finetune path here\n",
    "path_list = '''2020-10-15_10:14:21\n",
    "2020-10-15_10:18:37\n",
    "2020-10-15_12:11:49\n",
    "2020-10-15_12:21:06\n",
    "2020-10-15_12:32:58\n",
    "2020-10-15_12:56:54\n",
    "2020-10-15_13:02:38\n",
    "2020-10-15_13:05:55'''\n",
    "\n",
    "path_list = path_list.split('\\n')\n",
    "all_results_path_list = [pjoin(dirpath, p) for p in path_list]\n",
    "\n",
    "# in case of various weights location\n",
    "path_check_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "found_error = False\n",
    "try:\n",
    "    for all_results_path in all_results_path_list:\n",
    "        print('üìç testing .. all_results_path:', all_results_path, 'üìç')\n",
    "\n",
    "        nfolds = 1\n",
    "\n",
    "        results = []\n",
    "        test_results = []\n",
    "        done_subjects = []\n",
    "\n",
    "        t = pjoin(all_results_path, 'test_results.csv')\n",
    "\n",
    "        # read all folds results\n",
    "        df = pd.read_csv(pjoin(all_results_path, 'all_folds.csv'))\n",
    "\n",
    "        if type(df['random_round'].values[0]) != np.int64:\n",
    "            df = df.loc[df['random_round']!='-']\n",
    "\n",
    "        df = df.reset_index()\n",
    "\n",
    "        df[['random_round', 'K', 'nepochs', 'lr', 'loss', 'W', 'N1', 'N2', 'N3', 'REM', 'MF1']] = df[['random_round', \n",
    "                                                                                                      'K', 'nepochs', 'lr', 'loss',\n",
    "                                                                                                      'W', 'N1', \n",
    "                                                                                                      'N2', 'N3', \n",
    "                                                                                                      'REM', 'MF1']].apply(pd.to_numeric)\n",
    "\n",
    "        _, idx = np.unique(df['subj_id'].values, return_index=True)\n",
    "        subjects = df['subj_id'].values[np.sort(idx)]\n",
    "\n",
    "        pretrain_path = df['pretrain_path'].values[0]\n",
    "        channel = df['channel'].values[0]\n",
    "        max_epochs = np.max(df['nepochs'].values)\n",
    "        print('pretrain_path:', pretrain_path)\n",
    "        print('max_epochs:', max_epochs)\n",
    "\n",
    "        # average results from all random rounds in each subject & each set of hyperparams\n",
    "        results_df = pd.DataFrame(df.groupby(['subj_id', 'K', 'nepochs', 'lr'])['loss', \n",
    "                                                                         'W', 'N1', \n",
    "                                                                         'N2', 'N3', \n",
    "                                                                         'REM', 'MF1'].mean())\n",
    "\n",
    "        # get lowest loss of each subject\n",
    "        res_all = results_df.loc[results_df.groupby(['subj_id'])['loss'].idxmin()]\n",
    "        res_all = res_all.reset_index()\n",
    "\n",
    "        all_kappa_separate_round, all_mf1_separate_round, all_f1_separate_round, subjects_separate_round = [], [], [], []\n",
    "        all_acc_separate_round = []\n",
    "        all_lr_separate_round, all_nepochs_path_separate_round  = [], []\n",
    "\n",
    "        print('subjects:', subjects)\n",
    "        for subject_id in subjects:\n",
    "\n",
    "            if not subject_id in done_subjects:\n",
    "\n",
    "                # select only current subject\n",
    "                res = res_all.loc[res_all['subj_id'] == subject_id]\n",
    "                if len(res) == 0:\n",
    "                    print('Subject:', subject_id, 'Not Found.')\n",
    "                    continue\n",
    "\n",
    "                if len(res) > 1:\n",
    "                    raise Exception('More than 1 best hyperparams found.')\n",
    "\n",
    "                if len(res) == 1:\n",
    "                    # get best hyperparams of this subject\n",
    "                    best_k = res['K'].values[0]\n",
    "                    best_nepochs = res['nepochs'].values[0]\n",
    "                    best_lr = res['lr'].values[0]\n",
    "                    print('best_k:', best_k, 'best_nepochs:', best_nepochs, 'best_lr:', best_lr)\n",
    "\n",
    "                    # get finetune weight path of best hyperparams of this subject\n",
    "                    best_df = df.loc[(df['subj_id'] == subject_id) & \n",
    "                                     (df['K'] == best_k) & \n",
    "                                     (df['nepochs'] == best_nepochs) &\n",
    "                                     (df['lr'] == best_lr)\n",
    "                                    ]\n",
    "                    print(best_df)\n",
    "\n",
    "                    # save all rounds results tested with best params of this subject\n",
    "                    best_df.to_csv(pjoin(all_results_path, 'best_from_subject_'+str(subject_id)+'.csv'), index=False)\n",
    "\n",
    "                    # test with best hyperparams\n",
    "                    loss_all_round, acc_all_round, f1_all_round, kappa_all_round = [], [], [], []\n",
    "                    finetune_weight_path_all = []\n",
    "                    col = ['subj_id', 'K', 'lr', 'nepochs','pretrain_path', 'loss',\n",
    "                           'acc', 'W', 'N1', 'N2', 'N3', 'REM', 'MF1']\n",
    "                    for random_time in range(0, nfolds):\n",
    "                        print('testing random round:', random_time)\n",
    "                        random_seed = (random_time + 1) * 3\n",
    "\n",
    "                        best_df_row = best_df.loc[best_df['random_round']==random_time]\n",
    "                        finetune_weight_path = best_df_row['finetune_weight_path'].values[0]\n",
    "\n",
    "                        if pretrain_path == np.nan or str(pretrain_path) == 'nan':\n",
    "                            print('None pretrain path: use the saved weights, not fine-tune again.')\n",
    "\n",
    "                            # use ds_name from configure.finetune_dataset, but channel from all_folds.csv\n",
    "                            finetune = Finetune(best_k, \n",
    "                                                subject_id = subject_id,\n",
    "                                                model_pretrain_path = pretrain_path,\n",
    "                                                finetune_weight_path = finetune_weight_path,\n",
    "                                                seed = random_seed,\n",
    "                                                nepochs = [best_nepochs],\n",
    "                                                lr = best_lr,\n",
    "                                                ds_name = configure.finetune_dataset,\n",
    "                                                channel = channel\n",
    "                                               )\n",
    "                            finetune.init_model_ops()\n",
    "\n",
    "                            loss, acc, f1, kappa = finetune.predict(finetune_weight_path, best_epoch=best_nepochs)\n",
    "                        else:\n",
    "                            w_exist = os.path.exists(finetune_weight_path)\n",
    "                            print('finetune_weight_path:', finetune_weight_path, w_exist)  \n",
    "\n",
    "                            for path_check in path_check_list:\n",
    "                                if not w_exist:\n",
    "                                    path_tmp = pjoin(path_check,\n",
    "                                                     finetune_weight_path[7:])\n",
    "                                    print('Checking path_tmp:', path_tmp)\n",
    "                                    w_exist = os.path.exists(path_tmp)\n",
    "                                    if w_exist: \n",
    "                                        finetune_weight_path = path_tmp\n",
    "                                        print('finetune_weight_path changed:', finetune_weight_path, w_exist) \n",
    "                                else:\n",
    "                                    break\n",
    "\n",
    "\n",
    "                            if not w_exist:\n",
    "                                print('‚ÄºÔ∏è ALERT finetune_weight_path not found:', finetune_weight_path)\n",
    "                                bot.sendMsg('‚ö†Ô∏è NO PATH Found, created new one:', finetune_weight_path, \n",
    "                                           '@ all_results_path:', all_results_path)\n",
    "                                os.makedirs(finetune_weight_path)\n",
    "                                \n",
    "                            # use ds_name from configure.finetune_dataset, but channel from all_folds.csv\n",
    "                            finetune = Finetune(best_k, \n",
    "                                                subject_id = subject_id,\n",
    "                                                model_pretrain_path = pretrain_path,\n",
    "                                                finetune_weight_path = finetune_weight_path,\n",
    "                                                seed = random_seed,\n",
    "                                                nepochs = [best_nepochs],\n",
    "                                                lr = best_lr,\n",
    "                                                ds_name = configure.finetune_dataset,\n",
    "                                                channel = channel\n",
    "                                               )\n",
    "                            finetune.init_model_ops()\n",
    "                            \n",
    "                            wpath = pjoin(finetune_weight_path, \"model_iter\"+str(best_nepochs)+\".ckpt.index\")\n",
    "                            if not os.path.exists(wpath):\n",
    "                                raise Exception('Fine-tune weight not found: ' + str(wpath))\n",
    "                            else:\n",
    "                                loss, acc, f1, kappa = finetune.predict(finetune_weight_path, best_epoch=best_nepochs) \n",
    "                                \n",
    "                        all_lr_separate_round.append(best_lr)\n",
    "                        all_nepochs_path_separate_round.append(best_nepochs)\n",
    "                        loss_all_round.append(loss)\n",
    "                        acc_all_round.append(acc)\n",
    "                        f1_all_round.append(f1)\n",
    "                        kappa_all_round.append(kappa[0])\n",
    "                        all_kappa_separate_round.append(kappa[0])\n",
    "                        all_f1_separate_round.append(f1[0])\n",
    "                        all_mf1_separate_round.append(np.mean(f1[0]))\n",
    "                        all_acc_separate_round.append(acc[0])\n",
    "                        subjects_separate_round.append(subject_id)\n",
    "                        finetune_weight_path_all.append(finetune_weight_path)\n",
    "                        col.append('finetune_weight_path:round'+str(random_time))\n",
    "\n",
    "                        del finetune\n",
    "\n",
    "                    mean_loss = np.mean(loss_all_round)\n",
    "                    mean_acc = np.mean(acc_all_round)\n",
    "                    mean_f1_per_class = np.mean(f1_all_round, axis=0)[0]\n",
    "                    mf1 = np.mean(mean_f1_per_class)\n",
    "                    print('mean_f1_per_class:', mean_f1_per_class, 'mean_f1_per_class:', mf1)\n",
    "\n",
    "                    test_res = [subject_id, best_k, best_lr, best_nepochs, pretrain_path, mean_loss, mean_acc]\n",
    "                    test_res.extend(mean_f1_per_class)\n",
    "                    test_res.append(mf1)\n",
    "                    test_res.extend(finetune_weight_path_all)\n",
    "                    print(test_res)\n",
    "\n",
    "                    test_results.append(test_res)\n",
    "\n",
    "                    df2 = pd.DataFrame(test_results, columns=col)\n",
    "                    print(df2)\n",
    "                    df2.to_csv(pjoin(all_results_path, 'test_results.csv'), index=False)\n",
    "\n",
    "                    del test_res, df2\n",
    "\n",
    "        all_f1_separate_round = np.array(all_f1_separate_round)\n",
    "        print(all_f1_separate_round.shape)\n",
    "\n",
    "        df_kappa = pd.DataFrame({'subject_id': subjects_separate_round, \n",
    "                                 'K': [best_k] * len(subjects_separate_round),\n",
    "                                 'lr': all_lr_separate_round,\n",
    "                                 'nepochs': all_nepochs_path_separate_round,\n",
    "                                 'pretrain_path': [pretrain_path] * len(subjects_separate_round),\n",
    "                                 'kappa': all_kappa_separate_round,\n",
    "                                 'acc': all_acc_separate_round,\n",
    "                                 'f1_W': all_f1_separate_round[:,0],\n",
    "                                 'f1_N1': all_f1_separate_round[:,1],\n",
    "                                 'f1_N2': all_f1_separate_round[:,2],\n",
    "                                 'f1_N3': all_f1_separate_round[:,3],\n",
    "                                 'f1_R': all_f1_separate_round[:,4],\n",
    "                                 'mf1': all_mf1_separate_round \n",
    "                                })\n",
    "        df_kappa.to_csv(pjoin(all_results_path, 'test_results_separate_random_round.csv'), index=False)\n",
    "        print(df_kappa)\n",
    "\n",
    "        del df, results, test_results, done_subjects, df_kappa\n",
    "        del all_kappa_separate_round, all_mf1_separate_round, all_f1_separate_round, subjects_separate_round\n",
    "        del all_acc_separate_round, all_lr_separate_round, all_nepochs_path_separate_round\n",
    "        del loss_all_round, acc_all_round, f1_all_round, kappa_all_round, finetune_weight_path_all\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    bot.sendMsg('[üî¥ DONE with ERROR] FinetuneAndTestOnBestHyperparams-List', path_list[0])\n",
    "    found_error = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    print('done')\n",
    "    bot.sendMsg('[DONE] FinetuneAndTestOnBestHyperparams-List ü•≥ü•≥ü•≥', path_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
